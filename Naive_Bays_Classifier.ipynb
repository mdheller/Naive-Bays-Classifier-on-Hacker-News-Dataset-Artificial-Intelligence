{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------- \n",
    "# Assignment (include number)\n",
    "# Written by (include your name and student id)\n",
    "# For COMP 472 Section (your lab section) – Summer 2020\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import numpy as np\n",
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df = df[[\"Title\",\"Post Type\",\"year\"]]\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Post Type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Terminal: How the airport came to embody our n...</td>\n",
       "      <td>story</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not only is it possible to beat Google, it cou...</td>\n",
       "      <td>story</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DC’s war on rats goes digital</td>\n",
       "      <td>story</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Post Type  year\n",
       "0  Terminal: How the airport came to embody our n...     story  2018\n",
       "1  Not only is it possible to beat Google, it cou...     story  2018\n",
       "2                      DC’s war on rats goes digital     story  2018"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.loc[df['year'] == 2018]\n",
    "df_test = df.loc[df['year'] == 2019]\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4572"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df['Post Type'] == \"poll\"]\n",
    "len(df_train.loc[df['Post Type'] == \"story\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_dictionary = {}    # stores words in story class and their frequencies\n",
    "ask_hn_dictionary = {}    # stores words in ask_hn class and their frequencies\n",
    "show_hn_dictionary = {}    # stores words in show_hn class and their frequencies\n",
    "poll_dictionary = {}    # stores words in poll class and their frequencies\n",
    "vocabulary = set()    # stores all unique words present in dataset\n",
    "word_not_count = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictCheck(word):\n",
    "    if word not in story_dictionary:\n",
    "        story_dictionary[word] = 0\n",
    "    if word not in ask_hn_dictionary:\n",
    "        ask_hn_dictionary[word] = 0\n",
    "    if word not in show_hn_dictionary:\n",
    "        show_hn_dictionary[word] = 0\n",
    "    if word not in poll_dictionary:\n",
    "        poll_dictionary[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def word_count_directory(df_train):\n",
    "\n",
    "    # intialize no of spam and ham files\n",
    "    #  print(row['c1'], row['c2'])\n",
    "    no_of_story_class = len(df_train.loc[df['Post Type'] == \"story\"])\n",
    "    no_of_ask_hn_class = len(df_train.loc[df['Post Type'] == \"ask_hn\"])\n",
    "    no_of_show_hn_class = len(df_train.loc[df['Post Type'] == \"show_hn\"])\n",
    "    no_of_poll_class = len(df_train.loc[df['Post Type'] == \"poll\"])\n",
    "    \n",
    "    \n",
    "    for index, row in df_train.iterrows():\n",
    "        file_type = row['Post Type']\n",
    "        line = row['Title']\n",
    "        line = line.strip()    # Remove the leading spaces and newline character\n",
    "        lower_line = str.lower(line)    # Convert characters in line to lowercase to avoid case mismatch\n",
    "        \n",
    "        valid_words = re.split(\"[^a-zA-Z]\",lower_line) # filter words following the given regex\n",
    "        valid_words = list(filter(None, valid_words))   # filter words with length greater than 0\n",
    "        \n",
    "        res = re.sub('['+string.punctuation+'–‘«“”\"’\\']', ' ', lower_line).split() \n",
    "        res = list(filter(None, res))\n",
    "        invalid_words  = list(set(res) - set(valid_words))\n",
    "        for w in invalid_words:\n",
    "            word_not_count.add(w)\n",
    "        #print(valid_words,res,(list(set(res) - set(valid_words))) )\n",
    "        #print(\"--------------\")\n",
    "        \n",
    "        for word in valid_words:\n",
    "            if file_type == 'story':\n",
    "                # Check if the word is already in dictionary\n",
    "                if word in story_dictionary:\n",
    "                    story_dictionary[word] += 1\n",
    "                else:\n",
    "                    story_dictionary[word] = 1     # add word to dictionary with count 1\n",
    "                    vocabulary.add(word)     # add word to vocabulary set\n",
    "                    \n",
    "                    # if this word is not present in any other dictionary, add it with count 0\n",
    "                    dictCheck(word)\n",
    "\n",
    "            elif file_type == 'ask_hn':\n",
    "                # Check if the word is already in dictionary\n",
    "                if word in ask_hn_dictionary:\n",
    "                    ask_hn_dictionary[word] += 1\n",
    "                else:\n",
    "                    ask_hn_dictionary[word] = 1    # add word to dictionary with count 1\n",
    "                    vocabulary.add(word)    # add word to vocabulary set\n",
    "                    \n",
    "                    # if this word is not present in ham_dictionary, add it with count 0\n",
    "                    dictCheck(word)\n",
    "            \n",
    "            elif file_type == 'show_hn':\n",
    "                # Check if the word is already in dictionary\n",
    "                if word in show_hn_dictionary:\n",
    "                    show_hn_dictionary[word] += 1\n",
    "                else:\n",
    "                    show_hn_dictionary[word] = 1    # add word to dictionary with count 1\n",
    "                    vocabulary.add(word)    # add word to vocabulary set\n",
    "                    \n",
    "                    # if this word is not present in ham_dictionary, add it with count 0\n",
    "                    dictCheck(word)\n",
    "                    \n",
    "            elif file_type == 'poll':\n",
    "                # Check if the word is already in dictionary\n",
    "                if word in poll_dictionary:\n",
    "                    poll_dictionary[word] += 1\n",
    "                else:\n",
    "                    poll_dictionary[word] = 1    # add word to dictionary with count 1\n",
    "                    vocabulary.add(word)    # add word to vocabulary set\n",
    "                    \n",
    "                    # if this word is not present in ham_dictionary, add it with count 0\n",
    "                    dictCheck(word)\n",
    "        \n",
    "        \n",
    "\n",
    "       # word=''\n",
    "       # if any(word in lower_line for word in valid_words):\n",
    "       #     print(word,'|',line,'|',valid_words)\n",
    "       #     print(\"::::\")\n",
    "       #     print(res)\n",
    "       #     print(\"--------------\")\n",
    "\n",
    "        #print(line,valid_words)\n",
    "        \n",
    "    \n",
    "            \n",
    "        #print(no_of_story_class,no_of_ask_hn_class,no_of_show_hn_class,no_of_poll_class)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for file_path in file_list:\n",
    "        with open(file_path,encoding='latin-1') as infile:\n",
    "            # to store type of file 'spam' or 'ham'\n",
    "            file_type = ''\n",
    "            if 'spam' in file_path:\n",
    "                file_type = 'spam'\n",
    "                no_of_spam_files += 1\n",
    "            elif 'ham' in file_path:\n",
    "                file_type = 'ham'\n",
    "                no_of_ham_files += 1\n",
    "                \n",
    "            # Loop through each line of the file \n",
    "            for line in infile:\n",
    "                 \n",
    "                line = line.strip()    # Remove the leading spaces and newline character\n",
    "                lower_line = str.lower(line)    # Convert characters in line to lowercase to avoid case mismatch\n",
    "                valid_words = re.split('[^a-zA-Z]',lower_line) # filter words following the given regex\n",
    "                valid_words = list(filter(None, valid_words))   # filter words with length greater than 0\n",
    "                \n",
    "                # Iterate over each word in line \n",
    "                for word in valid_words:\n",
    "                    if file_type == 'ham':\n",
    "                        # Check if the word is already in dictionary\n",
    "                        if word in ham_dictionary:\n",
    "                            ham_dictionary[word] += 1\n",
    "                        else:\n",
    "                            ham_dictionary[word] = 1     # add word to dictionary with count 1\n",
    "                            vocabulary.add(word)     # add word to vocabulary set\n",
    "\n",
    "                            # if this word is not present in spam_dictionary, add it with count 0\n",
    "                            if word not in spam_dictionary:\n",
    "                                spam_dictionary[word] = 0\n",
    "\n",
    "                    elif file_type == 'spam':\n",
    "                        # Check if the word is already in dictionary\n",
    "                        if word in spam_dictionary:\n",
    "                            spam_dictionary[word] += 1\n",
    "                        else:\n",
    "                            spam_dictionary[word] = 1    # add word to dictionary with count 1\n",
    "                            vocabulary.add(word)    # add word to vocabulary set\n",
    "\n",
    "                            # if this word is not present in ham_dictionary, add it with count 0\n",
    "                            if word not in ham_dictionary:\n",
    "                                ham_dictionary[word] = 0\n",
    "    return no_of_spam_files,no_of_ham_files\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9544\n"
     ]
    }
   ],
   "source": [
    "word_count_directory(df_train)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9544\n",
      "9544\n",
      "9544\n",
      "9544\n"
     ]
    }
   ],
   "source": [
    "print(len(story_dictionary))\n",
    "print(len(ask_hn_dictionary))\n",
    "print(len(show_hn_dictionary))\n",
    "print(len(poll_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('remove_word.txt', 'w') as f:\n",
    "    f.writelines([\"%s\\n\" % item  for item in word_not_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0',\n",
       " '000',\n",
       " '00s',\n",
       " '02',\n",
       " '04',\n",
       " '06',\n",
       " '090',\n",
       " '0900…',\n",
       " '0x',\n",
       " '1',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '100b',\n",
       " '100k',\n",
       " '100m',\n",
       " '100th',\n",
       " '100x',\n",
       " '101',\n",
       " '10b',\n",
       " '10m',\n",
       " '10mb',\n",
       " '10th',\n",
       " '10x',\n",
       " '10yrs',\n",
       " '11',\n",
       " '110x',\n",
       " '116',\n",
       " '11776',\n",
       " '11ay',\n",
       " '11b',\n",
       " '11yr',\n",
       " '12',\n",
       " '125',\n",
       " '129th',\n",
       " '12m',\n",
       " '13',\n",
       " '130m',\n",
       " '134m',\n",
       " '13kb',\n",
       " '14',\n",
       " '140',\n",
       " '1401',\n",
       " '144',\n",
       " '15',\n",
       " '150',\n",
       " '150m',\n",
       " '155',\n",
       " '1553',\n",
       " '16',\n",
       " '168',\n",
       " '16b',\n",
       " '17',\n",
       " '17th',\n",
       " '18',\n",
       " '1803',\n",
       " '1873',\n",
       " '18800',\n",
       " '1891',\n",
       " '18b',\n",
       " '19',\n",
       " '1905',\n",
       " '1908',\n",
       " '1909',\n",
       " '1910',\n",
       " '1937',\n",
       " '1943',\n",
       " '1959',\n",
       " '1962',\n",
       " '1968',\n",
       " '1974',\n",
       " '1975',\n",
       " '1980',\n",
       " '1984',\n",
       " '1985',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1998',\n",
       " '1999',\n",
       " '1b',\n",
       " '1ghz',\n",
       " '1kb',\n",
       " '1m',\n",
       " '1s',\n",
       " '1v1',\n",
       " '1x1',\n",
       " '2',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '200b',\n",
       " '200m',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '201808',\n",
       " '2019',\n",
       " '2020',\n",
       " '2022',\n",
       " '2024',\n",
       " '2038',\n",
       " '2054',\n",
       " '20s',\n",
       " '20th',\n",
       " '21',\n",
       " '2100',\n",
       " '21b',\n",
       " '21st',\n",
       " '22',\n",
       " '220',\n",
       " '2200g',\n",
       " '226',\n",
       " '23',\n",
       " '2300',\n",
       " '2373',\n",
       " '23a',\n",
       " '24',\n",
       " '2400g',\n",
       " '240p',\n",
       " '25',\n",
       " '250',\n",
       " '250m',\n",
       " '256mb',\n",
       " '25b',\n",
       " '25th',\n",
       " '26',\n",
       " '275',\n",
       " '27b',\n",
       " '28',\n",
       " '28m',\n",
       " '299',\n",
       " '2b',\n",
       " '2d',\n",
       " '2fa',\n",
       " '2m',\n",
       " '3',\n",
       " '30',\n",
       " '300',\n",
       " '300m',\n",
       " '30fps',\n",
       " '30m',\n",
       " '30x',\n",
       " '31m',\n",
       " '32',\n",
       " '3301',\n",
       " '336',\n",
       " '343',\n",
       " '35',\n",
       " '35c3',\n",
       " '35k',\n",
       " '38',\n",
       " '390',\n",
       " '3am',\n",
       " '3bn',\n",
       " '3bsd',\n",
       " '3d',\n",
       " '3ghz',\n",
       " '3k',\n",
       " '3m',\n",
       " '3rd',\n",
       " '4',\n",
       " '40',\n",
       " '4000',\n",
       " '40b',\n",
       " '40s',\n",
       " '4185',\n",
       " '42floors',\n",
       " '43',\n",
       " '440',\n",
       " '45',\n",
       " '45m',\n",
       " '46',\n",
       " '480b',\n",
       " '48mm',\n",
       " '49',\n",
       " '4d',\n",
       " '4g',\n",
       " '4k',\n",
       " '4k60hz',\n",
       " '4m',\n",
       " '4mb',\n",
       " '5',\n",
       " '50',\n",
       " '500',\n",
       " '500m',\n",
       " '50m',\n",
       " '50tb',\n",
       " '51',\n",
       " '52',\n",
       " '520m',\n",
       " '52b',\n",
       " '52m',\n",
       " '53',\n",
       " '545',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '5b',\n",
       " '5g',\n",
       " '5m',\n",
       " '5th',\n",
       " '5x',\n",
       " '6',\n",
       " '60',\n",
       " '60ghz',\n",
       " '612m',\n",
       " '62',\n",
       " '625m',\n",
       " '629',\n",
       " '6389',\n",
       " '64',\n",
       " '6502',\n",
       " '66',\n",
       " '67',\n",
       " '6896',\n",
       " '6d',\n",
       " '6g',\n",
       " '6m',\n",
       " '7',\n",
       " '70',\n",
       " '700',\n",
       " '70m',\n",
       " '70millionjobs',\n",
       " '72',\n",
       " '721',\n",
       " '75',\n",
       " '750',\n",
       " '750fx',\n",
       " '750m',\n",
       " '76',\n",
       " '777',\n",
       " '78',\n",
       " '787',\n",
       " '7b',\n",
       " '7m',\n",
       " '7nm',\n",
       " '7y30',\n",
       " '8',\n",
       " '80',\n",
       " '802',\n",
       " '80s',\n",
       " '82',\n",
       " '82m',\n",
       " '845',\n",
       " '85m',\n",
       " '86',\n",
       " '8601',\n",
       " '867',\n",
       " '8752',\n",
       " '877',\n",
       " '88',\n",
       " '880',\n",
       " '8949',\n",
       " '8b',\n",
       " '8h',\n",
       " '9',\n",
       " '90',\n",
       " '900',\n",
       " '90s',\n",
       " '91',\n",
       " '9700k',\n",
       " '98',\n",
       " '99',\n",
       " '9gag',\n",
       " '9m',\n",
       " 'a220',\n",
       " 'abi2api',\n",
       " 'add‑on',\n",
       " 'arm64',\n",
       " 'av1',\n",
       " 'b2b',\n",
       " 'base58',\n",
       " 'börse',\n",
       " 'c2rust',\n",
       " 'c2x',\n",
       " 'cafés',\n",
       " 'call9',\n",
       " 'cecpq2',\n",
       " 'cg50',\n",
       " 'co2',\n",
       " 'co₂',\n",
       " 'cpe1704tks',\n",
       " 'cs2393',\n",
       " 'cw29',\n",
       " 'd3',\n",
       " 'dav1d',\n",
       " 'dota2',\n",
       " 'déraciné',\n",
       " 'ec2',\n",
       " 'erc20',\n",
       " 'es6',\n",
       " 'ev3',\n",
       " 'f1',\n",
       " 'ggplot2',\n",
       " 'h1',\n",
       " 'h1b',\n",
       " 'h2',\n",
       " 'h7',\n",
       " 'hq2',\n",
       " 'html5',\n",
       " 'i3',\n",
       " 'i7',\n",
       " 'image2image',\n",
       " 'image2text',\n",
       " 'ipv6',\n",
       " 'k8s',\n",
       " 'key2lyf',\n",
       " 'kobo360',\n",
       " 'librem13',\n",
       " 'm3',\n",
       " 'm4',\n",
       " 'missing…a',\n",
       " 'moiré',\n",
       " 'netv2',\n",
       " 'o157',\n",
       " 'p2p',\n",
       " 'p85',\n",
       " 'passé',\n",
       " 'perl6',\n",
       " 'pine64',\n",
       " 'preview3',\n",
       " 'protobuf3',\n",
       " 'pyqt5',\n",
       " 'q1',\n",
       " 'q2',\n",
       " 'q3',\n",
       " 'q4',\n",
       " 'r2d2',\n",
       " 'radare2',\n",
       " 'rené',\n",
       " 'renée',\n",
       " 'rl3',\n",
       " 's10',\n",
       " 's12',\n",
       " 's17',\n",
       " 's18',\n",
       " 's2',\n",
       " 's3',\n",
       " 's6',\n",
       " 's7',\n",
       " 's9',\n",
       " 'sense8',\n",
       " 'seq2seq',\n",
       " 'struct2depth',\n",
       " 'struts2',\n",
       " 't3',\n",
       " 'tech…',\n",
       " 'tessa88',\n",
       " 'thunderx2',\n",
       " 'top10',\n",
       " 'tpuv2',\n",
       " 'unity3d',\n",
       " 'us5723786',\n",
       " 'v0',\n",
       " 'v1',\n",
       " 'v2',\n",
       " 'v3',\n",
       " 'v4',\n",
       " 'v6',\n",
       " 'video2video',\n",
       " 'w12',\n",
       " 'w18',\n",
       " 'wikipedia2vec',\n",
       " 'wr840n',\n",
       " 'x360',\n",
       " 'x64',\n",
       " 'x86',\n",
       " '£4',\n",
       " 'ðapp',\n",
       " '\\u200bone',\n",
       " '\\u200d\\u200d',\n",
       " '—',\n",
       " '€7680',\n",
       " '√log',\n",
       " 'ꓘamerka',\n",
       " '\\ue5d4'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'9700k', 'c2rust', '12', '25b', 's18', '100x', '2005', '90s', '6d', '1937', '2008', '50m', 'h2', '5', '43', 'ðapp', '78', '10b', 'video2video', 'rl3', 'x64', 'dav1d', '2100', '3bsd', '22', '200b', 'c2x', '700', '6896', '7', '14', '88', 'p2p', '3k', '1989', '5th', 'q1', '—', '9gag', '520m', 'renée', '2011', 's9', 'moiré', 'co₂', '27b', '35', '52', 'pine64', '25th', '28', 'v2', '2200g', '45', 'abi2api', '00s', '721', 'v4', 'image2text', '11', '256mb', 'perl6', '3d', '1ghz', '19', '49', '32', '16b', '1988', 's17', 'key2lyf', '21', '2002', '5g', '336', '867', 'protobuf3', 'passé', '802', '2016', '24', '1908', '1s', '1891', '18', '85m', 'r2d2', '18b', '7y30', '1959', '500', '51', 'cg50', 'v3', '8h', '21st', '250m', '750fx', 'kobo360', 'b2b', '2000', '30fps', '£4', '130m', '612m', '2015', '2020', '2007', '2054', '168', '4000', '880', 'co2', '629', 'f1', 'v0', '5m', '2024', '2m', 'rené', '70', '18800', '20th', '2012', 'v6', '7b', '144', 'x86', '3m', '11ay', '35c3', '201808', '299', 'ipv6', 'ꓘamerka', '90', '2004', '2b', 'preview3', 't3', '45m', 'av1', 'unity3d', 'p85', '1905', '10yrs', '1000', '21b', 'm4', '67', '52m', '240p', '9', '30m', '1kb', '1995', '4mb', '125', 's3', '√log', '15', '9m', 'cafés', 'missing…a', '40s', '8601', '1910', 'd3', '343', '1985', '13', '1996', '72', 'h1', '10x', 's2', '140', 'sense8', '777', '090', '8752', '1993', '1998', '60', '845', '129th', 'h1b', 'erc20', '10', '1909', '2019', '6g', '3rd', 'h7', 'i3', '€7680', '1984', '1968', '200m', 'add‑on', '2017', 'q3', '440', '11776', '2006', 'déraciné', 'ev3', '62', '\\u200d\\u200d', 'ec2', 'o157', '877', 'image2image', '6', '2018', '1401', '110x', '8b', '28m', '3bn', '16', '50', '750', 'cpe1704tks', '100m', '40b', '2001', 'börse', '31m', '2013', 'cw29', '2', '1962', '4m', '3301', '5b', '1', '150m', 'base58', 'librem13', '70millionjobs', '1m', 'radare2', 'q2', '1994', '275', 'w18', '26', '8949', '23', '4k60hz', '17th', '1943', 'tech…', '48mm', '17', '5x', 'arm64', '\\u200bone', '66', 'thunderx2', 'top10', '57', '134m', '1975', '000', 'tessa88', '40', '02', '250', 'k8s', '750m', '8', '4k', '390', '0x', '42floors', '98', '59', '76', '46', 'm3', 'struts2', 'call9', '20s', 'dota2', 'hq2', '480b', 's7', '2fa', '23a', 's10', 'wikipedia2vec', '52b', 'netv2', '1999', '11b', '7nm', '545', '100k', 'tpuv2', '20', '53', '13kb', '12m', '10th', '75', 'seq2seq', 'html5', '100th', '3', '1803', 'v1', '99', '80s', '04', 'us5723786', '30x', 'a220', '100', '1990', '101', '4185', '2d', '50tb', 'w12', '1980', '7m', '3am', '155', '1b', '500m', '70m', '10m', '25', '11yr', '6m', '3ghz', '625m', 'i7', '64', '30', '2009', '86', '91', '2022', 'es6', '58', '900', '35k', '300m', '116', '787', 'pyqt5', '82m', 'wr840n', 's6', '2003', 's12', '1v1', '60ghz', '6502', '220', '300', '1x1', '4', '2010', '0', '2300', '150', '82', '200', '10mb', '4g', '2014', '38', '1873', 'cs2393', 'struct2depth', 'x360', '06', '\\ue5d4', '226', '2400g', '2038', '1553', 'q4', '6389', '0900…', '1974', 'cecpq2', 'ggplot2', '100b', '2373', '80', '4d'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
