{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------- \n",
    "# Assignment (include number)\n",
    "# Written by (include your name and student id)\n",
    "# For COMP 472 Section (your lab section) – Summer 2020\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import numpy as np\n",
    "import string "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Extract the data and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df = df[[\"Title\",\"Post Type\",\"year\"]]\n",
    "\n",
    "df_train = df.loc[df['year'] == 2018]\n",
    "df_test = df.loc[df['year'] == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_dictionary = {}      # stores words in story class and their frequencies\n",
    "ask_hn_dictionary = {}     # stores words in ask_hn class and their frequencies\n",
    "show_hn_dictionary = {}    # stores words in show_hn class and their frequencies\n",
    "poll_dictionary = {}       # stores words in poll class and their frequencies\n",
    "vocabulary = set()         # stores all unique words present in dataset\n",
    "word_not_count = set()     # stores all unique removed words present in dataset\n",
    "stopword = set()\n",
    "story_cp_dictionary = {}   # stores words in story class and their conditional probabilities\n",
    "ask_hn_cp_dictionary = {}  # stores words in ask_hn class and their conditional probabilities\n",
    "show_hn_cp_dictionary = {} # stores words in show_hn class and their conditional probabilities\n",
    "poll_cp_dictionary = {}    # stores words in poll class and their conditional probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clear():\n",
    "    \n",
    "    global story_dictionary      # stores words in story class and their frequencies\n",
    "    global ask_hn_dictionary      # stores words in ask_hn class and their frequencies\n",
    "    global show_hn_dictionary    # stores words in show_hn class and their frequencies\n",
    "    global poll_dictionary        # stores words in poll class and their frequencies\n",
    "    global story_cp_dictionary    # stores words in story class and their conditional probabilities\n",
    "    global ask_hn_cp_dictionary   # stores words in ask_hn class and their conditional probabilities\n",
    "    global show_hn_cp_dictionary # stores words in show_hn class and their conditional probabilities\n",
    "    global poll_cp_dictionary     # stores words in poll class and their conditional probabilities\n",
    "    global vocabulary         # stores all unique words present in dataset\n",
    "    global word_not_count     # stores all unique removed words present in dataset\n",
    "    global stopword \n",
    "\n",
    "    story_dictionary = {}      # stores words in story class and their frequencies\n",
    "    ask_hn_dictionary = {}     # stores words in ask_hn class and their frequencies\n",
    "    show_hn_dictionary = {}    # stores words in show_hn class and their frequencies\n",
    "    poll_dictionary = {}       # stores words in poll class and their frequencies\n",
    "    vocabulary = set()         # stores all unique words present in dataset\n",
    "    word_not_count = set()     # stores all unique removed words present in dataset\n",
    "    stopword = set()\n",
    "    story_cp_dictionary = {}   # stores words in story class and their conditional probabilities\n",
    "    ask_hn_cp_dictionary = {}  # stores words in ask_hn class and their conditional probabilities\n",
    "    show_hn_cp_dictionary = {} # stores words in show_hn class and their conditional probabilities\n",
    "    poll_cp_dictionary = {}    # stores words in poll class and their conditional probabilities\n",
    "    \n",
    "    # story_dictionary.clear()\n",
    "    # ask_hn_dictionary.clear()\n",
    "    # show_hn_dictionary.clear()\n",
    "    # poll_dictionary.clear()\n",
    "    # story_cp_dictionary.clear()\n",
    "    # ask_hn_cp_dictionary.clear()\n",
    "    # show_hn_cp_dictionary.clear()\n",
    "    # poll_cp_dictionary.clear()\n",
    "    # vocabulary.clear()\n",
    "    # word_not_count.clear()\n",
    "    # stopword.clear()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dictCheck(word)  =  if this word is not present in any other dictionary, add it with count 0\n",
    "word = All words after removing invalid words \n",
    "\n",
    "'''\n",
    "\n",
    "def dictCheck(word):\n",
    "    \n",
    "    global story_dictionary      # stores words in story class and their frequencies\n",
    "    global ask_hn_dictionary      # stores words in ask_hn class and their frequencies\n",
    "    global show_hn_dictionary    # stores words in show_hn class and their frequencies\n",
    "    global poll_dictionary        # stores words in poll class and their frequencies\n",
    "\n",
    "    \n",
    "    if word not in story_dictionary:\n",
    "        story_dictionary[word] = 0\n",
    "    if word not in ask_hn_dictionary:\n",
    "        ask_hn_dictionary[word] = 0\n",
    "    if word not in show_hn_dictionary:\n",
    "        show_hn_dictionary[word] = 0\n",
    "    if word not in poll_dictionary:\n",
    "        poll_dictionary[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "word_count_directory(df_train)  = build vocabulary from training set\n",
    "df_train = dataframe of training set (year=2018)\n",
    "\n",
    "'''\n",
    "\n",
    "def word_count_directory(df_train,ch):\n",
    "    \n",
    "    global story_dictionary      # stores words in story class and their frequencies\n",
    "    global ask_hn_dictionary      # stores words in ask_hn class and their frequencies\n",
    "    global show_hn_dictionary    # stores words in show_hn class and their frequencies\n",
    "    global poll_dictionary        # stores words in poll class and their frequencies\n",
    "    global vocabulary         # stores all unique words present in dataset\n",
    "    global word_not_count     # stores all unique removed words present in dataset\n",
    "    global stopword \n",
    "    print(type(vocabulary))\n",
    "\n",
    "    # intialize no of story, ask_hn, show_hn and poll class \n",
    "    no_of_story_class = len(df_train.loc[df['Post Type'] == \"story\"])\n",
    "    no_of_ask_hn_class = len(df_train.loc[df['Post Type'] == \"ask_hn\"])\n",
    "    no_of_show_hn_class = len(df_train.loc[df['Post Type'] == \"show_hn\"])\n",
    "    no_of_poll_class = len(df_train.loc[df['Post Type'] == \"poll\"])\n",
    "    \n",
    "    if ch == 1:\n",
    "        with open('stopwords.txt',encoding='latin-1') as infile:\n",
    "            for line1 in infile:\n",
    "                line1 = line1.strip()    # Remove the leading spaces and newline character\n",
    "                lower_line1 = str.lower(line1)\n",
    "                stopword.add(lower_line1)\n",
    "                \n",
    "    for index, row in df_train.iterrows():\n",
    "        class_type = row['Post Type']\n",
    "        line = row['Title']\n",
    "        line = line.strip()             # Remove the leading spaces and newline character\n",
    "        lower_line = str.lower(line)    # Convert characters in line to lowercase to avoid case mismatch\n",
    "        \n",
    "        valid_words = re.split(\"[^a-zA-Z]\",lower_line)       # filter words following the given regex\n",
    "        valid_words = list(filter(None, valid_words))        # filter words with length greater than 0\n",
    "        \n",
    "        res = re.sub('['+string.punctuation+'–‘«“”\"’\\']', ' ', lower_line).split()  # remove all special character ans numbers\n",
    "        res = list(filter(None, res))\n",
    "        invalid_words  = list(set(res) - set(valid_words))   # diff. between valid & invalid words\n",
    "        for w in invalid_words:\n",
    "            word_not_count.add(w)\n",
    "        \n",
    "        \n",
    "        for word in valid_words:\n",
    "            if ch == 1:\n",
    "                if word in stopword:\n",
    "                    word_not_count.add(word)\n",
    "                    continue\n",
    "                \n",
    "            \n",
    "            # check for class type\n",
    "            if class_type == 'story':\n",
    "                \n",
    "                # Check if the word is already in dictionary\n",
    "                if word in story_dictionary:\n",
    "                    story_dictionary[word] += 1\n",
    "                else:\n",
    "                    story_dictionary[word] = 1     # add word to dictionary with count 1\n",
    "                    vocabulary.add(word)           # add word to vocabulary set\n",
    "                    \n",
    "            elif class_type == 'ask_hn':\n",
    "\n",
    "                if word in ask_hn_dictionary:\n",
    "                    ask_hn_dictionary[word] += 1\n",
    "                else:\n",
    "                    ask_hn_dictionary[word] = 1   \n",
    "                    vocabulary.add(word)\n",
    "                                \n",
    "            elif class_type == 'show_hn':\n",
    "\n",
    "                if word in show_hn_dictionary:\n",
    "                    show_hn_dictionary[word] += 1\n",
    "                else:\n",
    "                    show_hn_dictionary[word] = 1  \n",
    "                    vocabulary.add(word)\n",
    "                                        \n",
    "            elif class_type == 'poll':\n",
    "\n",
    "                if word in poll_dictionary:\n",
    "                    poll_dictionary[word] += 1\n",
    "                else:\n",
    "                    poll_dictionary[word] = 1   \n",
    "                    vocabulary.add(word)\n",
    "         \n",
    "           # if this word is not present in any other dictionary, add it with count 0\n",
    "            dictCheck(word)\n",
    "                    \n",
    "    return no_of_story_class,no_of_ask_hn_class,no_of_show_hn_class,no_of_poll_class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create_model() = build a probabilistic model from the training set.\n",
    "vocabulary = vocabulary with all the words it contains in Title which is At 2018\n",
    "story_dictionary = word frequency map for class story\n",
    "ask_hn_dictionary = word frequency map for class ask_hn\n",
    "show_hn_dictionary = word frequency map for class show_hn\n",
    "poll_dictionary = word frequency map for class poll\n",
    "\n",
    "'''\n",
    "def create_model(vocabulary,story_dictionary,ask_hn_dictionary,show_hn_dictionary,poll_dictionary,ch):\n",
    "    \n",
    "\n",
    "    global story_cp_dictionary    # stores words in story class and their conditional probabilities\n",
    "    global ask_hn_cp_dictionary   # stores words in ask_hn class and their conditional probabilities\n",
    "    global show_hn_cp_dictionary # stores words in show_hn class and their conditional probabilities\n",
    "    global poll_cp_dictionary     # stores words in poll class and their conditional probabilities\n",
    "\n",
    "\n",
    "    if ch==0:\n",
    "        f = open(\"model-2018.txt\",\"w+\")    # creating file that would store the model\n",
    "    elif ch==1:\n",
    "        f = open(\"stopword-model.txt\",\"w+\")    # creating file that would store the model\n",
    "            \n",
    "    N = len(vocabulary)    # getting size of vocabulary\n",
    "    delta = 0.5    # smoothing value\n",
    "    \n",
    "    smoothed_N = (delta * N)\n",
    "    # calculating smoothed denominator for calculating condinational probability of story class\n",
    "    story_denominator = sum(story_dictionary.values()) + smoothed_N\n",
    "    \n",
    "    # calculating smoothed denominator for calculating condinational probability of ask_hn class\n",
    "    ask_hn_denominator = sum(ask_hn_dictionary.values()) + smoothed_N\n",
    "    \n",
    "    # calculating smoothed denominator for calculating condinational probability of show_hn class\n",
    "    show_hn_denominator = sum(show_hn_dictionary.values()) + smoothed_N\n",
    "    \n",
    "    # calculating smoothed denominator for calculating condinational probability of poll class\n",
    "    poll_denominator = sum(poll_dictionary.values()) + smoothed_N\n",
    "    \n",
    "    for i,word in enumerate(vocabulary):\n",
    "        \n",
    "        freq_in_story = story_dictionary[word]                               # frequency of word in story dictionary\n",
    "        c_p_in_story = (freq_in_story + delta) / story_denominator         # conditional probabiltiy of word in story class\n",
    "        freq_in_ask_hn = ask_hn_dictionary[word]                             # frequency of word in ask_hn dictionary\n",
    "        c_p_in_ask_hn = (freq_in_ask_hn + delta) / ask_hn_denominator      # conditional probabiltiy of word in ask_hn class\n",
    "        freq_in_show_hn = show_hn_dictionary[word]                             # frequency of word in show_hn dictionary\n",
    "        c_p_in_show_hn = (freq_in_show_hn + delta) / show_hn_denominator   # conditional probabiltiy of word in show_hn class\n",
    "        freq_in_poll = poll_dictionary[word]                               # frequency of word in poll dictionary\n",
    "        c_p_in_poll = (freq_in_poll + delta) / poll_denominator            # conditional probabiltiy of word in poll class\n",
    "        \n",
    "        story_cp_dictionary[word] = c_p_in_story\n",
    "        ask_hn_cp_dictionary[word] = c_p_in_ask_hn\n",
    "        show_hn_cp_dictionary[word] = c_p_in_show_hn\n",
    "        poll_cp_dictionary[word] = c_p_in_poll\n",
    "        \n",
    "        # writing all data to model-2018.txt\n",
    "        f.write(str(i+1)+'  '+word+'  '+str(freq_in_story)+'  '+str( \"{:.8f}\".format(float( c_p_in_story )) )+'  '+str(freq_in_ask_hn)+'  '+str( \"{:.8f}\".format(float( c_p_in_ask_hn )) )+'  '+str(freq_in_show_hn)+'  '+str( \"{:.8f}\".format(float( c_p_in_show_hn )) )+'  '+str(freq_in_poll)+'  '+str( \"{:.8f}\".format(float( c_p_in_poll )) )+'\\n')\n",
    "    \n",
    "    f.close()    # closing the file\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run classifier on the 2019 testing dataset and create a single file named baseline-result.txt with your classification results. \n",
    "\n",
    "For each test file, baseline-result.txt will contain:\n",
    "    1. a line counter, followed by 2 spaces\n",
    "    2. the name of the test post Title, followed by 2 spaces\n",
    "    3. the classification as given by your classifier (the label story, ask-hn, show-hn or poll), followed by 2 spaces\n",
    "    4. the score of the class story as given by your classifier, followed by 2 spaces\n",
    "    5. the score of the class ask-hn as given by your classifier, followed by 2 spaces\n",
    "    6. the score of the class show-hn as given by your classifier, followed by 2 spaces\n",
    "    7. the score of the class poll as given by your classifier, followed by 2 spaces\n",
    "    8. the correct classification of post, followed by 2 spaces\n",
    "    9. the label right or wrong (depending on the case), followed by a carriage return.\n",
    "\n",
    "'''\n",
    "def evaluate_the_model(ch):\n",
    "    \n",
    "    global story_dictionary      # stores words in story class and their frequencies\n",
    "    global ask_hn_dictionary      # stores words in ask_hn class and their frequencies\n",
    "    global show_hn_dictionary    # stores words in show_hn class and their frequencies\n",
    "    global poll_dictionary        # stores words in poll class and their frequencies\n",
    "    global story_cp_dictionary    # stores words in story class and their conditional probabilities\n",
    "    global ask_hn_cp_dictionary   # stores words in ask_hn class and their conditional probabilities\n",
    "    global show_hn_cp_dictionary # stores words in show_hn class and their conditional probabilities\n",
    "    global poll_cp_dictionary     # stores words in poll class and their conditional probabilities\n",
    "    global vocabulary         # stores all unique words present in dataset\n",
    "    global word_not_count     # stores all unique removed words present in dataset\n",
    "    global stopword \n",
    "    \n",
    "    \n",
    "    # applying log10 on prior probabilities\n",
    "    if prior_prob_of_story == 0:\n",
    "        log_of_story=0\n",
    "    else:\n",
    "        log_of_story = math.log10(prior_prob_of_story)\n",
    "    if prior_prob_of_ask_hn == 0:\n",
    "        log_of_ask_hn=0\n",
    "    else:\n",
    "        log_of_ask_hn = math.log10(prior_prob_of_ask_hn)\n",
    "    if prior_prob_of_show_hn == 0:\n",
    "        log_of_show_hn=0\n",
    "    else:\n",
    "        log_of_show_hn = math.log10(prior_prob_of_show_hn)\n",
    "    if prior_prob_of_poll == 0:\n",
    "        log_of_poll=0\n",
    "    else:\n",
    "        log_of_poll = math.log10(prior_prob_of_poll)\n",
    "\n",
    "    score_log_story   =  log_of_story      # score for story class\n",
    "    score_log_ask_hn  =  log_of_ask_hn     # score for ask_hn class\n",
    "    score_log_show_hn =  log_of_show_hn    # score for show_hn class\n",
    "    score_log_poll    =  log_of_poll       # score for poll class\n",
    "\n",
    "    if ch == 0:\n",
    "        f = open(\"baseline-result.txt\", \"w+\")   # 'w+' for reading and writing\n",
    "    elif ch == 1:\n",
    "        f = open(\"stopword-result.txt\", \"w+\")   # 'w+' for reading and writing\n",
    "        \n",
    "    f.truncate(0)\n",
    "\n",
    "    temp_counter=0\n",
    "    right_classify=0\n",
    "    wrong_classify=0\n",
    "    \n",
    "    for index, row in df_test.iterrows():\n",
    "        temp_counter=temp_counter+1\n",
    "        correct_class_type = row['Post Type']\n",
    "        line = row['Title']\n",
    "        line = line.strip()                                  # Remove the leading spaces and newline character\n",
    "        lower_line = str.lower(line)                         # Convert characters in line to lowercase to avoid case mismatch\n",
    "        valid_words = re.split(\"[^a-zA-Z]\",lower_line)       # filter words following the given regex\n",
    "        valid_words = list(filter(None, valid_words))        # filter words with length greater than 0\n",
    "    \n",
    "        for word in valid_words:\n",
    "            if word in vocabulary:\n",
    "                score_log_story = float(score_log_story) + math.log10(story_cp_dictionary[word])        # add log10 of conditional probability of word in story_cp_dictionary\n",
    "                score_log_ask_hn = float(score_log_ask_hn) + math.log10(ask_hn_cp_dictionary[word])     # add log10 of conditional probability of word in ask_hn_cp_dictionary\n",
    "                score_log_show_hn = float(score_log_show_hn) + math.log10(show_hn_cp_dictionary[word])  # add log10 of conditional probability of word in show_hn_cp_dictionary\n",
    "                score_log_poll = float(score_log_poll) + math.log10(poll_cp_dictionary[word])           # add log10 of conditional probability of word in poll_cp_dictionary\n",
    "\n",
    "        score_list = [score_log_story,score_log_ask_hn,score_log_show_hn,score_log_poll ]\n",
    "        score_index =  score_list.index(max(score_list))\n",
    "    \n",
    "        if score_index == 0:\n",
    "            predicted_class_type = \"story\"\n",
    "        elif score_index == 1:\n",
    "            predicted_class_type = \"ask_hn\"\n",
    "        elif score_index == 2:\n",
    "            predicted_class_type = \"show_hn\"\n",
    "        elif score_index == 3:\n",
    "            predicted_class_type = \"poll\"\n",
    "    \n",
    "        if(correct_class_type == predicted_class_type):\n",
    "            label = \"right\"\n",
    "            right_classify=right_classify+1\n",
    "        else:\n",
    "            label = \"wrong\"\n",
    "            wrong_classify=wrong_classify+1\n",
    "    \n",
    "        # format scores to appropriate string value\n",
    "        score_log_story = str( \"{:.8f}\".format(float(score_log_story)))\n",
    "        score_log_ask_hn = str( \"{:.8f}\".format(float(score_log_ask_hn)))\n",
    "        score_log_show_hn = str( \"{:.8f}\".format(float(score_log_show_hn)))\n",
    "        score_log_poll = str( \"{:.8f}\".format(float(score_log_poll)))\n",
    "        \n",
    "        # writing results to result.txt\n",
    "        f.write(str(str(temp_counter)+\"  \"+str(line)+\"  \"+str(predicted_class_type)+\"  \"+str(score_log_story)+\"  \"+str(score_log_ask_hn)+\"  \"+str(score_log_show_hn)+\"  \"+str(score_log_poll)+\"  \"+str(correct_class_type)+\"  \"+str(label)+\"\\n\"))\n",
    "\n",
    "    f.close()    # closing file\n",
    "    return right_classify,wrong_classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Use ML Classifier to test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n",
      "4572 222 206 0\n",
      "9544 9544 9544 9544 9544\n",
      "4606 394\n"
     ]
    }
   ],
   "source": [
    "no_of_story_class,no_of_ask_hn_class,no_of_show_hn_class,no_of_poll_class = word_count_directory(df_train,0)\n",
    "total_no_of_files = no_of_story_class+no_of_ask_hn_class+no_of_show_hn_class+no_of_poll_class\n",
    "\n",
    "\n",
    "print(no_of_story_class,no_of_ask_hn_class,no_of_show_hn_class,no_of_poll_class)\n",
    "# prior probabilities of four class\n",
    "prior_prob_of_story = no_of_story_class / total_no_of_files\n",
    "prior_prob_of_ask_hn = no_of_ask_hn_class / total_no_of_files\n",
    "prior_prob_of_show_hn = no_of_show_hn_class / total_no_of_files\n",
    "prior_prob_of_poll = no_of_poll_class / total_no_of_files\n",
    "\n",
    "print(len(vocabulary),len(story_dictionary),len(ask_hn_dictionary),len(show_hn_dictionary),len(poll_dictionary))\n",
    "\n",
    "vocabulary = sorted(vocabulary)    # sorting the vocabulary to maintain order in model.txt\n",
    "\n",
    "# put all the removed/invalid words in an file named “remove_word.txt”.\n",
    "with open('vocabulary.txt', 'w') as f:\n",
    "    f.writelines([\"%s\\n\" % item  for item in vocabulary])\n",
    "    \n",
    "# put all the removed/invalid words in an file named “remove_word.txt”.\n",
    "with open('remove_word.txt', 'w') as f:\n",
    "    f.writelines([\"%s\\n\" % item  for item in word_not_count])\n",
    "    \n",
    "create_model(vocabulary,story_dictionary,ask_hn_dictionary,show_hn_dictionary,poll_dictionary,0)\n",
    "right_classify,wrong_classify=evaluate_the_model(0)\n",
    "print(right_classify,wrong_classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Experiments with the classifier\n",
    "### Experiment 1: Stop-word Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n",
      "<class 'set'>\n",
      "9405 9405 9405 9405 9405\n",
      "4569 431\n"
     ]
    }
   ],
   "source": [
    "data_clear()\n",
    "no_of_story_class,no_of_ask_hn_class,no_of_show_hn_class,no_of_poll_class = word_count_directory(df_train,1)\n",
    "total_no_of_files = no_of_story_class+no_of_ask_hn_class+no_of_show_hn_class+no_of_poll_class\n",
    "\n",
    "print(type(vocabulary))\n",
    "\n",
    "# prior probabilities of four class\n",
    "prior_prob_of_story = no_of_story_class / total_no_of_files\n",
    "prior_prob_of_ask_hn = no_of_ask_hn_class / total_no_of_files\n",
    "prior_prob_of_show_hn = no_of_show_hn_class / total_no_of_files\n",
    "prior_prob_of_poll = no_of_poll_class / total_no_of_files\n",
    "\n",
    "print(len(vocabulary),len(story_dictionary),len(ask_hn_dictionary),len(show_hn_dictionary),len(poll_dictionary))\n",
    "\n",
    "vocabulary = sorted(vocabulary)   # sorting the vocabulary to maintain order in model.txt\n",
    "\n",
    "\n",
    "# put all the removed/invalid words in an file named “remove_word.txt”.\n",
    "with open('stopword-vocabulary.txt', 'w') as f:\n",
    "    f.writelines([\"%s\\n\" % item  for item in vocabulary])\n",
    "    \n",
    "# put all the removed/invalid words in an file named “remove_word.txt”.\n",
    "with open('stopword-remove_word.txt', 'w') as f:\n",
    "    f.writelines([\"%s\\n\" % item  for item in word_not_count])\n",
    "    \n",
    "create_model(vocabulary,story_dictionary,ask_hn_dictionary,show_hn_dictionary,poll_dictionary,1)\n",
    "right_classify,wrong_classify=evaluate_the_model(1)\n",
    "print(right_classify,wrong_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-86-76a2fe70f0cf>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-86-76a2fe70f0cf>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <class 'set'>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<class 'set'>\n",
    "0 9405 9405 9405 9405"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
