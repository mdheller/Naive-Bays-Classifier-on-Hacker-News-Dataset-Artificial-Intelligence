{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------- \n",
    "# Assignment (include number)\n",
    "# Written by (include your name and student id)\n",
    "# For COMP 472 Section (your lab section) – Summer 2020\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import numpy as np\n",
    "import string "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Extract the data and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df = df[[\"Title\",\"Post Type\",\"year\"]]\n",
    "\n",
    "df_train = df.loc[df['year'] == 2018]\n",
    "df_test = df.loc[df['year'] == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_dictionary = {}      # stores words in story class and their frequencies\n",
    "ask_hn_dictionary = {}     # stores words in ask_hn class and their frequencies\n",
    "show_hn_dictionary = {}    # stores words in show_hn class and their frequencies\n",
    "poll_dictionary = {}       # stores words in poll class and their frequencies\n",
    "story_cp_dictionary = {}   # stores words in story class and their conditional probabilities\n",
    "ask_hn_cp_dictionary = {}  # stores words in ask_hn class and their conditional probabilities\n",
    "show_hn_cp_dictionary = {} # stores words in show_hn class and their conditional probabilities\n",
    "poll_cp_dictionary = {}    # stores words in poll class and their conditional probabilities\n",
    "vocabulary = set()         # stores all unique words present in dataset\n",
    "word_not_count = set()     # stores all unique removed words present in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dictCheck(word)  =  if this word is not present in any other dictionary, add it with count 0\n",
    "word = All words after removing invalid words \n",
    "\n",
    "'''\n",
    "\n",
    "def dictCheck(word):\n",
    "    if word not in story_dictionary:\n",
    "        story_dictionary[word] = 0\n",
    "    if word not in ask_hn_dictionary:\n",
    "        ask_hn_dictionary[word] = 0\n",
    "    if word not in show_hn_dictionary:\n",
    "        show_hn_dictionary[word] = 0\n",
    "    if word not in poll_dictionary:\n",
    "        poll_dictionary[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "word_count_directory(df_train)  = build vocabulary from training set\n",
    "df_train = dataframe of training set (year=2018)\n",
    "\n",
    "'''\n",
    "\n",
    "def word_count_directory(df_train):\n",
    "\n",
    "    # intialize no of story, ask_hn, show_hn and poll class \n",
    "    no_of_story_class = len(df_train.loc[df['Post Type'] == \"story\"])\n",
    "    no_of_ask_hn_class = len(df_train.loc[df['Post Type'] == \"ask_hn\"])\n",
    "    no_of_show_hn_class = len(df_train.loc[df['Post Type'] == \"show_hn\"])\n",
    "    no_of_poll_class = len(df_train.loc[df['Post Type'] == \"poll\"])\n",
    "    \n",
    "    \n",
    "    for index, row in df_train.iterrows():\n",
    "        class_type = row['Post Type']\n",
    "        line = row['Title']\n",
    "        line = line.strip()             # Remove the leading spaces and newline character\n",
    "        lower_line = str.lower(line)    # Convert characters in line to lowercase to avoid case mismatch\n",
    "        \n",
    "        valid_words = re.split(\"[^a-zA-Z]\",lower_line)       # filter words following the given regex\n",
    "        valid_words = list(filter(None, valid_words))        # filter words with length greater than 0\n",
    "        \n",
    "        res = re.sub('['+string.punctuation+'–‘«“”\"’\\']', ' ', lower_line).split()  # remove all special character ans numbers\n",
    "        res = list(filter(None, res))\n",
    "        invalid_words  = list(set(res) - set(valid_words))   # diff. between valid & invalid words\n",
    "        for w in invalid_words:\n",
    "            word_not_count.add(w)\n",
    "            \n",
    "        \n",
    "        for word in valid_words:\n",
    "            \n",
    "            # check for class type\n",
    "            if class_type == 'story':\n",
    "                \n",
    "                # Check if the word is already in dictionary\n",
    "                if word in story_dictionary:\n",
    "                    story_dictionary[word] += 1\n",
    "                else:\n",
    "                    story_dictionary[word] = 1     # add word to dictionary with count 1\n",
    "                    vocabulary.add(word)           # add word to vocabulary set\n",
    "                    \n",
    "            elif class_type == 'ask_hn':\n",
    "\n",
    "                if word in ask_hn_dictionary:\n",
    "                    ask_hn_dictionary[word] += 1\n",
    "                else:\n",
    "                    ask_hn_dictionary[word] = 1   \n",
    "                    vocabulary.add(word)\n",
    "                                \n",
    "            elif class_type == 'show_hn':\n",
    "\n",
    "                if word in show_hn_dictionary:\n",
    "                    show_hn_dictionary[word] += 1\n",
    "                else:\n",
    "                    show_hn_dictionary[word] = 1  \n",
    "                    vocabulary.add(word)\n",
    "                                        \n",
    "            elif class_type == 'poll':\n",
    "\n",
    "                if word in poll_dictionary:\n",
    "                    poll_dictionary[word] += 1\n",
    "                else:\n",
    "                    poll_dictionary[word] = 1   \n",
    "                    vocabulary.add(word)\n",
    "         \n",
    "           # if this word is not present in any other dictionary, add it with count 0\n",
    "            dictCheck(word)\n",
    "                    \n",
    "    return no_of_story_class,no_of_ask_hn_class,no_of_show_hn_class,no_of_poll_class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_story_class,no_of_ask_hn_class,no_of_show_hn_class,no_of_poll_class = word_count_directory(df_train)\n",
    "total_no_of_files = no_of_story_class+no_of_ask_hn_class+no_of_show_hn_class+no_of_poll_class\n",
    "\n",
    "# prior probabilities of four class\n",
    "prior_prob_of_story = no_of_story_class / total_no_of_files\n",
    "prior_prob_of_ask_hn = no_of_ask_hn_class / total_no_of_files\n",
    "prior_prob_of_show_hn = no_of_show_hn_class / total_no_of_files\n",
    "prior_prob_of_poll = no_of_poll_class / total_no_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9544\n",
      "9544\n",
      "9544\n",
      "9544\n",
      "9544\n"
     ]
    }
   ],
   "source": [
    "print(len(vocabulary))\n",
    "print(len(story_dictionary))\n",
    "print(len(ask_hn_dictionary))\n",
    "print(len(show_hn_dictionary))\n",
    "print(len(poll_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = sorted(vocabulary)    # sorting the vocabulary to maintain order in model.txt\n",
    "\n",
    "# put all the removed/invalid words in an file named “remove_word.txt”.\n",
    "with open('vocabulary.txt', 'w') as f:\n",
    "    f.writelines([\"%s\\n\" % item  for item in vocabulary])\n",
    "    \n",
    "# put all the removed/invalid words in an file named “remove_word.txt”.\n",
    "with open('remove_word.txt', 'w') as f:\n",
    "    f.writelines([\"%s\\n\" % item  for item in word_not_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create_model() = build a probabilistic model from the training set.\n",
    "vocabulary = vocabulary with all the words it contains in Title which is At 2018\n",
    "story_dictionary = word frequency map for class story\n",
    "ask_hn_dictionary = word frequency map for class ask_hn\n",
    "show_hn_dictionary = word frequency map for class show_hn\n",
    "poll_dictionary = word frequency map for class poll\n",
    "\n",
    "'''\n",
    "def create_model(vocabulary,story_dictionary,ask_hn_dictionary,show_hn_dictionary,poll_dictionary):\n",
    "    \n",
    "    f = open(\"model-2018.txt\",\"w+\")    # creating file that would store the model\n",
    "    N = len(vocabulary)    # getting size of vocabulary\n",
    "    delta = 0.5    # smoothing value\n",
    "    \n",
    "    smoothed_N = (delta * N)\n",
    "    # calculating smoothed denominator for calculating condinational probability of story class\n",
    "    story_denominator = sum(story_dictionary.values()) + smoothed_N\n",
    "    \n",
    "    # calculating smoothed denominator for calculating condinational probability of ask_hn class\n",
    "    ask_hn_denominator = sum(ask_hn_dictionary.values()) + smoothed_N\n",
    "    \n",
    "    # calculating smoothed denominator for calculating condinational probability of show_hn class\n",
    "    show_hn_denominator = sum(show_hn_dictionary.values()) + smoothed_N\n",
    "    \n",
    "    # calculating smoothed denominator for calculating condinational probability of poll class\n",
    "    poll_denominator = sum(poll_dictionary.values()) + smoothed_N\n",
    "    \n",
    "    for i,word in enumerate(vocabulary):\n",
    "        \n",
    "        freq_in_story = story_dictionary[word]                               # frequency of word in story dictionary\n",
    "        c_p_in_story = (freq_in_story + delta) / story_denominator         # conditional probabiltiy of word in story class\n",
    "        freq_in_ask_hn = ask_hn_dictionary[word]                             # frequency of word in ask_hn dictionary\n",
    "        c_p_in_ask_hn = (freq_in_ask_hn + delta) / ask_hn_denominator      # conditional probabiltiy of word in ask_hn class\n",
    "        freq_in_show_hn = show_hn_dictionary[word]                             # frequency of word in show_hn dictionary\n",
    "        c_p_in_show_hn = (freq_in_show_hn + delta) / show_hn_denominator   # conditional probabiltiy of word in show_hn class\n",
    "        freq_in_poll = poll_dictionary[word]                               # frequency of word in poll dictionary\n",
    "        c_p_in_poll = (freq_in_poll + delta) / poll_denominator            # conditional probabiltiy of word in poll class\n",
    "        \n",
    "        story_cp_dictionary[word] = c_p_in_story\n",
    "        ask_hn_cp_dictionary[word] = c_p_in_ask_hn\n",
    "        show_hn_cp_dictionary[word] = c_p_in_show_hn\n",
    "        poll_cp_dictionary[word] = c_p_in_poll\n",
    "        \n",
    "        # writing all data to model-2018.txt\n",
    "        f.write(str(i+1)+'  '+word+'  '+str(freq_in_story)+'  '+str( \"{:.8f}\".format(float( c_p_in_story )) )+'  '+str(freq_in_ask_hn)+'  '+str( \"{:.8f}\".format(float( c_p_in_ask_hn )) )+'  '+str(freq_in_show_hn)+'  '+str( \"{:.8f}\".format(float( c_p_in_show_hn )) )+'  '+str(freq_in_poll)+'  '+str( \"{:.8f}\".format(float( c_p_in_poll )) )+'\\n')\n",
    "    \n",
    "    f.close()    # closing the file\n",
    "    \n",
    "create_model(vocabulary,story_dictionary,ask_hn_dictionary,show_hn_dictionary,poll_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Use ML Classifier to test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# applying log10 on prior probabilities\n",
    "if prior_prob_of_story == 0:\n",
    "    log_of_story=0\n",
    "else:\n",
    "    log_of_story = math.log10(prior_prob_of_story)\n",
    "if prior_prob_of_ask_hn == 0:\n",
    "    log_of_ask_hn=0\n",
    "else:\n",
    "    log_of_ask_hn = math.log10(prior_prob_of_ask_hn)\n",
    "if prior_prob_of_show_hn == 0:\n",
    "    log_of_show_hn=0\n",
    "else:\n",
    "    log_of_show_hn = math.log10(prior_prob_of_show_hn)\n",
    "if prior_prob_of_poll == 0:\n",
    "    log_of_poll=0\n",
    "else:\n",
    "    log_of_poll = math.log10(prior_prob_of_poll)\n",
    "\n",
    "score_log_story   =  log_of_story      # score for story class\n",
    "score_log_ask_hn  =  log_of_ask_hn     # score for ask_hn class\n",
    "score_log_show_hn =  log_of_show_hn    # score for show_hn class\n",
    "score_log_poll    =  log_of_poll       # score for poll class\n",
    "\n",
    "f = open(\"baseline-result.txt\", \"w+\")   # 'w+' for reading and writing\n",
    "f.truncate(0)\n",
    "\n",
    "temp_counter=0\n",
    "right_classify=0\n",
    "wrong_classify=0\n",
    "for index, row in df_test.iterrows():\n",
    "    temp_counter=temp_counter+1\n",
    "    correct_class_type = row['Post Type']\n",
    "    line = row['Title']\n",
    "    line = line.strip()                                  # Remove the leading spaces and newline character\n",
    "    lower_line = str.lower(line)                         # Convert characters in line to lowercase to avoid case mismatch\n",
    "    valid_words = re.split(\"[^a-zA-Z]\",lower_line)       # filter words following the given regex\n",
    "    valid_words = list(filter(None, valid_words))        # filter words with length greater than 0\n",
    "    \n",
    "    for word in valid_words:\n",
    "        if word in vocabulary:\n",
    "            score_log_story = float(score_log_story) + math.log10(story_cp_dictionary[word])        # add log10 of conditional probability of word in story_cp_dictionary\n",
    "            score_log_ask_hn = float(score_log_ask_hn) + math.log10(ask_hn_cp_dictionary[word])     # add log10 of conditional probability of word in ask_hn_cp_dictionary\n",
    "            score_log_show_hn = float(score_log_show_hn) + math.log10(show_hn_cp_dictionary[word])  # add log10 of conditional probability of word in show_hn_cp_dictionary\n",
    "            score_log_poll = float(score_log_poll) + math.log10(poll_cp_dictionary[word])           # add log10 of conditional probability of word in poll_cp_dictionary\n",
    "\n",
    "    score_list = [score_log_story,score_log_ask_hn,score_log_show_hn,score_log_poll ]\n",
    "    score_index =  score_list.index(max(score_list))\n",
    "    \n",
    "    if score_index == 0:\n",
    "        predicted_class_type = \"story\"\n",
    "    elif score_index == 1:\n",
    "        predicted_class_type = \"ask_hn\"\n",
    "    elif score_index == 2:\n",
    "        predicted_class_type = \"show_hn\"\n",
    "    elif score_index == 3:\n",
    "        predicted_class_type = \"poll\"\n",
    "    \n",
    "    if(correct_class_type == predicted_class_type):\n",
    "        label = \"right\"\n",
    "        right_classify=right_classify+1\n",
    "    else:\n",
    "        label = \"wrong\"\n",
    "        wrong_classify=wrong_classify+1\n",
    "    \n",
    "    # format scores to appropriate string value\n",
    "    score_log_story = str( \"{:.8f}\".format(float(score_log_story)))\n",
    "    score_log_ask_hn = str( \"{:.8f}\".format(float(score_log_ask_hn)))\n",
    "    score_log_show_hn = str( \"{:.8f}\".format(float(score_log_show_hn)))\n",
    "    score_log_poll = str( \"{:.8f}\".format(float(score_log_poll)))\n",
    "        \n",
    "    # writing results to result.txt\n",
    "    f.write(str(str(temp_counter)+\"  \"+str(line)+\"  \"+str(predicted_class_type)+\"  \"+str(score_log_story)+\"  \"+str(score_log_ask_hn)+\"  \"+str(score_log_show_hn)+\"  \"+str(score_log_poll)+\"  \"+str(correct_class_type)+\"  \"+str(label)+\"\\n\"))\n",
    "\n",
    "f.close()    # closing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4606"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_classify"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
